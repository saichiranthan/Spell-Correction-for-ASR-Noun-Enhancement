{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce3e242",
   "metadata": {},
   "source": [
    "# Baseline models for Spell Correction\n",
    "\n",
    "### 1. Setup and Data Loading\n",
    "Lets set up our environment by importing the necessary libraries, then load the training and validation sets that was created and saved in the previous notebook.Using the ast library to safely convert the string representation of the target_nouns list back into an actual list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bcfe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded with 7000 rows.\n",
      "Validation data loaded with 1500 rows.\n",
      "Vocabulary built with 9188 unique words.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from collections import Counter\n",
    "import ast # To safely evaluate string representations of lists\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the preprocessed datasets\n",
    "try:\n",
    "    train_df = pd.read_csv('../dataset/train.csv')\n",
    "    val_df = pd.read_csv('../dataset/validation.csv')\n",
    "    \n",
    "    # Safely convert the 'target_nouns' column from string back to a list\n",
    "    val_df['target_nouns'] = val_df['target_nouns'].apply(ast.literal_eval)\n",
    "    \n",
    "    print(f\"Training data loaded with {len(train_df)} rows.\")\n",
    "    print(f\"Validation data loaded with {len(val_df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.csv' and 'validation.csv' are present.\")\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "# Build the vocabulary from the training data for both models\n",
    "if not train_df.empty:\n",
    "    all_correct_words = ' '.join(train_df['correct_cleaned_baseline'].astype(str)).split()\n",
    "    vocabulary = set(all_correct_words)\n",
    "    print(f\"Vocabulary built with {len(vocabulary)} unique words.\")\n",
    "else:\n",
    "    vocabulary = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ba5f3",
   "metadata": {},
   "source": [
    "### 2. Baseline Model 1: Dictionary & Levenshtein Distance\n",
    "\n",
    "This model uses a direct dictionary-based approach. For each word in an incorrect sentence, it checks for its existence in the vocabulary. If the word is not found, the model searches the vocabulary for the word with the smallest Levenshtein (edit) distance and replaces it, provided the distance is within a set threshold (e.g., 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79023155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Levenshtein correction to the validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041b5d16fef1440090d157375af1a599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein correction complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_cleaned_baseline</th>\n",
       "      <th>levenshtein_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amydio forte is a powerful medication often us...</td>\n",
       "      <td>imidio forte is a powerful medication often us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>provera 40 contains medroxyprogesterone acetat...</td>\n",
       "      <td>provera-d contains medrexiprogesterone acetate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ceemi-o is a popular over-the-counter medicati...</td>\n",
       "      <td>imci h is a popular over-the-counter medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l-arginine sr is a popular supplement known fo...</td>\n",
       "      <td>lrg9-sr is a popular supplement known for its ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correct_cleaned_baseline  \\\n",
       "0  patients are recommended to consult their heal...   \n",
       "1  amydio forte is a powerful medication often us...   \n",
       "2  provera 40 contains medroxyprogesterone acetat...   \n",
       "3  ceemi-o is a popular over-the-counter medicati...   \n",
       "4  l-arginine sr is a popular supplement known fo...   \n",
       "\n",
       "                               levenshtein_predicted  \n",
       "0  patients are recommended to consult their heal...  \n",
       "1  imidio forte is a powerful medication often us...  \n",
       "2  provera-d contains medrexiprogesterone acetate...  \n",
       "3  imci h is a popular over-the-counter medicatio...  \n",
       "4  lrg9-sr is a popular supplement known for its ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correction_cache = {}\n",
    "MAX_EDIT_DISTANCE = 2 # Max distance for a correction\n",
    "\n",
    "def get_levenshtein_correction(word, vocab):\n",
    "    \"\"\"Finds the best correction based on Levenshtein distance.\"\"\"\n",
    "    if word in correction_cache:\n",
    "        return correction_cache[word]\n",
    "    if word in vocab:\n",
    "        correction_cache[word] = word\n",
    "        return word\n",
    "\n",
    "    # Find the best suggestion\n",
    "    suggestions = [(edit_distance(word, v_word), v_word) for v_word in vocab if abs(len(word) - len(v_word)) <= MAX_EDIT_DISTANCE]\n",
    "    \n",
    "    if not suggestions:\n",
    "        correction_cache[word] = word # No suggestions found\n",
    "        return word\n",
    "\n",
    "    best_suggestion = min(suggestions, key=lambda x: x[0])\n",
    "    \n",
    "    # Use suggestion if within threshold\n",
    "    if best_suggestion[0] <= MAX_EDIT_DISTANCE:\n",
    "        correction_cache[word] = best_suggestion[1]\n",
    "        return best_suggestion[1]\n",
    "    else:\n",
    "        correction_cache[word] = word\n",
    "        return word\n",
    "\n",
    "def baseline_sentence_correction(sentence, vocab):\n",
    "    \"\"\"Applies Levenshtein correction to an entire sentence.\"\"\"\n",
    "    words = sentence.split()\n",
    "    corrected_words = [get_levenshtein_correction(word, vocab) for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Apply correction to the validation set\n",
    "if not val_df.empty:\n",
    "    print(\"Applying Levenshtein correction to the validation set...\")\n",
    "    val_df['levenshtein_predicted'] = val_df['incorrect_cleaned_baseline'].progress_apply(\n",
    "        lambda x: baseline_sentence_correction(x, vocabulary)\n",
    "    )\n",
    "    print(\"Levenshtein correction complete.\")\n",
    "    # Display sample results\n",
    "    display(val_df[['correct_cleaned_baseline', 'levenshtein_predicted']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806f487",
   "metadata": {},
   "source": [
    "### 3. Baseline Model 2: N-gram Language \n",
    "The N-gram model enhances the Levenshtein approach by adding context. For a misspelled word, it first generates a list of potential candidates (using edit distance). Then, it uses a pre-built N-gram (bigram and trigram) model to score each candidate based on the probability of it appearing with the preceding words. The candidate that forms the most probable sequence is chosen as the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f2baa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building N-gram models...\n",
      "N-gram models built.\n",
      "\n",
      "Applying N-gram correction to the validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cbe031cbbb4efb820c13573f27eb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram correction complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_cleaned_baseline</th>\n",
       "      <th>ngram_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amydio forte is a powerful medication often us...</td>\n",
       "      <td>imidio forte is a powerful medication often us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>provera 40 contains medroxyprogesterone acetat...</td>\n",
       "      <td>provera-d contains medrexiprogesterone acetate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ceemi-o is a popular over-the-counter medicati...</td>\n",
       "      <td>some low is a popular over-the-counter medicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l-arginine sr is a popular supplement known fo...</td>\n",
       "      <td>lrg9-sr is a popular supplement known for its ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correct_cleaned_baseline  \\\n",
       "0  patients are recommended to consult their heal...   \n",
       "1  amydio forte is a powerful medication often us...   \n",
       "2  provera 40 contains medroxyprogesterone acetat...   \n",
       "3  ceemi-o is a popular over-the-counter medicati...   \n",
       "4  l-arginine sr is a popular supplement known fo...   \n",
       "\n",
       "                                     ngram_predicted  \n",
       "0  patients are recommended to consult their heal...  \n",
       "1  imidio forte is a powerful medication often us...  \n",
       "2  provera-d contains medrexiprogesterone acetate...  \n",
       "3  some low is a popular over-the-counter medicat...  \n",
       "4  lrg9-sr is a popular supplement known for its ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 1: Build N-gram models from training data ---\n",
    "print(\"Building N-gram models...\")\n",
    "bigram_counts = Counter()\n",
    "trigram_counts = Counter()\n",
    "\n",
    "for sentence in train_df['correct_cleaned_baseline']:\n",
    "    words = ['<s>'] + sentence.split() + ['</s>'] # Add start/end tokens\n",
    "    bigram_counts.update(zip(words, words[1:]))\n",
    "    trigram_counts.update(zip(words, words[1:], words[2:]))\n",
    "\n",
    "print(\"N-gram models built.\")\n",
    "\n",
    "# --- Step 2: Implement the N-gram correction logic ---\n",
    "def get_ngram_correction(previous_word, current_word, vocab):\n",
    "    \"\"\"Generates candidates and scores them using N-gram context.\"\"\"\n",
    "    if current_word in vocab:\n",
    "        return current_word\n",
    "\n",
    "    # Generate candidates (similar to Levenshtein model)\n",
    "    suggestions = [v_word for v_word in vocab if edit_distance(current_word, v_word) <= MAX_EDIT_DISTANCE]\n",
    "    if not suggestions:\n",
    "        return current_word\n",
    "\n",
    "    # Score candidates based on bigram probability\n",
    "    best_candidate = current_word\n",
    "    max_score = -1\n",
    "\n",
    "    for candidate in suggestions:\n",
    "        # Simple scoring: use the frequency count from our bigram model\n",
    "        score = bigram_counts.get((previous_word, candidate), 0)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_candidate = candidate\n",
    "            \n",
    "    return best_candidate\n",
    "\n",
    "def ngram_sentence_correction(sentence, vocab):\n",
    "    \"\"\"Applies N-gram based correction to an entire sentence.\"\"\"\n",
    "    words = ['<s>'] + sentence.split() # Add start token for context\n",
    "    corrected_words = []\n",
    "    \n",
    "    for i in range(1, len(words)):\n",
    "        previous_word = words[i-1]\n",
    "        current_word = words[i]\n",
    "        corrected_word = get_ngram_correction(previous_word, current_word, vocab)\n",
    "        corrected_words.append(corrected_word)\n",
    "        words[i] = corrected_word # Update for context of next word\n",
    "        \n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# --- Step 3: Apply N-gram correction to the validation set ---\n",
    "if not val_df.empty:\n",
    "    print(\"\\nApplying N-gram correction to the validation set...\")\n",
    "    val_df['ngram_predicted'] = val_df['incorrect_cleaned_baseline'].progress_apply(\n",
    "        lambda x: ngram_sentence_correction(x, vocabulary)\n",
    "    )\n",
    "    print(\"N-gram correction complete.\")\n",
    "    # Display sample results\n",
    "    display(val_df[['correct_cleaned_baseline', 'ngram_predicted']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ecd5b",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "We will now evaluate both models on the four specified metrics.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "##### Sentence Accuracy:\n",
    "- **Significance**: This is the most stringent metric. It measures the percentage of predicted sentences that are a perfect, character-for-character match with the ground truth sentences. A high score indicates the model is capable of producing completely error-free transcriptions.\n",
    "- **Calculation**: It is calculated by counting the number of predicted sentences that exactly match the correct sentences, then dividing by the total number of sentences.\n",
    "\n",
    "##### Word Accuracy:\n",
    "- **Significance**: This metric provides a more granular measure of performance by calculating the percentage of correctly predicted words. It is useful for understanding the overall quality of the transcription, even if entire sentences are not perfect.\n",
    "- **Calculation**: It is calculated by comparing the predicted and true sentences word-by-word, summing the number of matching words, and dividing by the total number of words in the true sentences .\n",
    "\n",
    "\n",
    "##### Character Error Rate (CER):\n",
    "\n",
    "- **Significance**: CER measures the dissimilarity between the predicted and true sentences at the character level. It is especially relevant for spell correction tasks as it quantifies how \"close\" a prediction is to the correct version. A lower CER indicates a better performance.\n",
    "- **Calculation**: CER is computed using the Levenshtein distance, which determines the minimum number of single-character edits (insertions, deletions, or substitutions) needed to change the predicted sentence into the correct one. This total edit distance is then normalized by dividing by the total number of characters in the correct sentences.\n",
    "\n",
    "\n",
    "##### Noun Accuracy:\n",
    "\n",
    "\n",
    "- **Significance**: As per the assignment's focus, this is a crucial domain-specific metric. It specifically evaluates the model's ability to correctly identify and transcribe nouns, which are often the critical medication names and medical terms in this context.\n",
    "- **Calculation**: First, nouns are extracted from both the true (target) sentences and the model's predicted sentences using POS tagging. The metric then measures the overlap between these two sets of nouns, calculated as the number of correctly predicted nouns divided by the total number of nouns in the true sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761c4c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance Comparison ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_09d2d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09d2d_level0_col0\" class=\"col_heading level0 col0\" >Sentence Accuracy</th>\n",
       "      <th id=\"T_09d2d_level0_col1\" class=\"col_heading level0 col1\" >Word Accuracy</th>\n",
       "      <th id=\"T_09d2d_level0_col2\" class=\"col_heading level0 col2\" >CER</th>\n",
       "      <th id=\"T_09d2d_level0_col3\" class=\"col_heading level0 col3\" >Noun Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09d2d_level0_row0\" class=\"row_heading level0 row0\" >Levenshtein</th>\n",
       "      <td id=\"T_09d2d_row0_col0\" class=\"data row0 col0\" >7.00%</td>\n",
       "      <td id=\"T_09d2d_row0_col1\" class=\"data row0 col1\" >68.64%</td>\n",
       "      <td id=\"T_09d2d_row0_col2\" class=\"data row0 col2\" >4.00%</td>\n",
       "      <td id=\"T_09d2d_row0_col3\" class=\"data row0 col3\" >73.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09d2d_level0_row1\" class=\"row_heading level0 row1\" >N-gram</th>\n",
       "      <td id=\"T_09d2d_row1_col0\" class=\"data row1 col0\" >6.53%</td>\n",
       "      <td id=\"T_09d2d_row1_col1\" class=\"data row1 col1\" >68.53%</td>\n",
       "      <td id=\"T_09d2d_row1_col2\" class=\"data row1 col2\" >4.19%</td>\n",
       "      <td id=\"T_09d2d_row1_col3\" class=\"data row1 col3\" >73.52%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x147032fbc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_sentence_accuracy(df, true_col, pred_col):\n",
    "    correct_sentences = (df[true_col] == df[pred_col]).sum()\n",
    "    total_sentences = len(df)\n",
    "    return (correct_sentences / total_sentences) * 100\n",
    "\n",
    "def calculate_word_accuracy(df, true_col, pred_col):\n",
    "    total_words = 0\n",
    "    correct_words = 0\n",
    "    for _, row in df.iterrows():\n",
    "        true_words = str(row[true_col]).split()\n",
    "        pred_words = str(row[pred_col]).split()\n",
    "        total_words += len(true_words)\n",
    "        for i in range(min(len(true_words), len(pred_words))):\n",
    "            if true_words[i] == pred_words[i]:\n",
    "                correct_words += 1\n",
    "    return (correct_words / total_words) * 100 if total_words > 0 else 0\n",
    "\n",
    "def calculate_cer(df, true_col, pred_col):\n",
    "    total_distance = 0\n",
    "    total_chars = 0\n",
    "    for _, row in df.iterrows():\n",
    "        true_sent = str(row[true_col])\n",
    "        pred_sent = str(row[pred_col])\n",
    "        total_distance += edit_distance(true_sent, pred_sent)\n",
    "        total_chars += len(true_sent)\n",
    "    return (total_distance / total_chars) * 100 if total_chars > 0 else 0\n",
    "\n",
    "def calculate_noun_accuracy(df, true_nouns_col, pred_sent_col):\n",
    "    total_true_nouns = 0\n",
    "    correctly_predicted_nouns = 0\n",
    "    for _, row in df.iterrows():\n",
    "        true_nouns = set(row[true_nouns_col])\n",
    "        pred_doc = nlp(str(row[pred_sent_col]))\n",
    "        pred_nouns = set([token.text for token in pred_doc if token.pos_ in ('NOUN', 'PROPN')])\n",
    "        correctly_predicted_nouns += len(true_nouns.intersection(pred_nouns))\n",
    "        total_true_nouns += len(true_nouns)\n",
    "    return (correctly_predicted_nouns / total_true_nouns) * 100 if total_true_nouns > 0 else 0\n",
    "\n",
    "# --- Function to run all evaluations ---\n",
    "def evaluate_model(df, model_pred_col):\n",
    "    true_col = 'correct_cleaned_baseline'\n",
    "    true_nouns_col = 'target_nouns'\n",
    "    \n",
    "    sa = calculate_sentence_accuracy(df, true_col, model_pred_col)\n",
    "    wa = calculate_word_accuracy(df, true_col, model_pred_col)\n",
    "    cer = calculate_cer(df, true_col, model_pred_col)\n",
    "    na = calculate_noun_accuracy(df, true_nouns_col, model_pred_col)\n",
    "    \n",
    "    return {\"Sentence Accuracy\": sa, \"Word Accuracy\": wa, \"CER\": cer, \"Noun Accuracy\": na}\n",
    "\n",
    "# Evaluate Levenshtein Model\n",
    "levenshtein_results = evaluate_model(val_df, 'levenshtein_predicted')\n",
    "\n",
    "# Evaluate N-gram Model\n",
    "ngram_results = evaluate_model(val_df, 'ngram_predicted')\n",
    "\n",
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame([levenshtein_results, ngram_results], index=['Levenshtein', 'N-gram'])\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "display(results_df.style.format(\"{:.2f}%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef436ec1",
   "metadata": {},
   "source": [
    "### 5.**Analysis and Conclusion** \n",
    "\n",
    "#### **Performance Summary**\n",
    "\n",
    "The evaluation of the baseline models on the validation set produced the following results:\n",
    "\n",
    "| Model | Sentence Accuracy | Word Accuracy | CER | Noun Accuracy |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Levenshtein** | 7.00% | 68.64% | 4.00% | 73.93% |\n",
    "| **N-gram** | 6.53% | 68.53% | 4.19% | 73.52% |\n",
    "\n",
    "\n",
    "#### **Analysis**\n",
    "\n",
    "* **Key Finding**: The simpler **Levenshtein model unexpectedly outperformed the N-gram model** on all metrics. This suggests the N-gram model's limited context, likely affected by data sparsity, offered no practical advantage.\n",
    "\n",
    "* **Metric Insights**:\n",
    "    * The **Noun Accuracy is higher than the overall Word Accuracy**, which is a positive sign that the models are more effective on the assignment's primary targets (medical nouns)[cite: 8, 17].\n",
    "    * The **very low Sentence Accuracy (~7%)** confirms that achieving perfect sentence correction with these methods is highly challenging.\n",
    "    * The **low Character Error Rate (CER)**, despite poor word/sentence scores, indicates the models can fix small typos but fail on complex issues like **segmentation errors** (`health care` vs. `healthcare`), which was a major error type identified in the EDA\n",
    "\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "These baseline models successfully establish a performance benchmark but their limitations are clear. Their inability to handle complex, structural errors like word segmentation provides a **strong, data-driven justification for progressing to advanced transformer-based models like T5**, as outlined in the assignment. These advanced architectures are specifically designed to overcome such weaknesses by interpreting the context of the entire sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
