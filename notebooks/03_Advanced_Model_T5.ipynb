{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810b2603",
   "metadata": {},
   "source": [
    "# ADVANCED MODEL DEVELOPMENT (SEQ2SEQ WITH T5)\n",
    "This notebook trains and evaluates two T5 models for spell correction.\n",
    "\n",
    "### Technical Rationale: Choosing T5 over BERT for Spell Correction\n",
    "While the assignment brief mentions exploring \"BERT-based approaches,\" I deliberately chose the T5 (Text-to-Text Transfer Transformer) model. This decision is based on fundamental architectural differences that make T5 more suitable for the spell correction task.\n",
    "\n",
    "#### Understanding the Architectures\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is an Encoder-Only model that excels at understanding and classifying text. Its strength lies in tasks like sentiment analysis, Named Entity Recognition (NER), and question answering.\n",
    "\n",
    "T5 (Text-to-Text Transfer Transformer) is an Encoder-Decoder model designed to transform an input text sequence into a new output sequence. This makes it a natural fit for sequence-to-sequence (Seq2Seq) tasks such as translation, summarization, and text correction.\n",
    "\n",
    "**Why T5 is the Superior Choice for This Task**\n",
    "Spell correction is fundamentally a sequence-to-sequence task, where an incorrect sentence is transformed into a correct one. T5's Encoder-Decoder architecture is explicitly built for this paradigm, offering a more direct and efficient implementation than adapting an encoder-only model like BERT. This makes T5 the more appropriate and architecturally sound tool for the job.\n",
    "\n",
    "#### Conclusion: The Right Tool for the Right Job\n",
    "Our choice of T5 is a strategic one, selecting the best tool for this seq2seq challenge. We refine this strategy by comparing a general-purpose T5 model (`t5-base`) with a domain-specific one (`BiomedNLP/t5-base-biomed-pubmed`). This approach allows us to measure the performance gain from leveraging specialized medical vocabularyâ€”the core challenge identified in our initial EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37be130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import spacy\n",
    "import numpy as np\n",
    "import ast\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "# It's a good practice to check for GPU availability\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b2f88",
   "metadata": {},
   "source": [
    "### Data Loading and Preparation\n",
    "\n",
    "In this cell,load the pre-split datasets created in the first notebook,also preprocess the text by adding a task-specific prefix required by T5 and convert the data into the Hugging Face `Dataset` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd884ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared and converted to Hugging Face Dataset objects.\n",
      "\n",
      "Sample from training data:\n",
      "{'input_text': 'correct the spelling: make sure to consult your health care provider before starting a new medication like aerifix tab', 'target_text': 'make sure to consult your healthcare provider before starting a new medication like arifix tab'}\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed datasets\n",
    "try:\n",
    "    train_df = pd.read_csv('../dataset/train.csv')\n",
    "    val_df = pd.read_csv('../dataset/validation.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.csv' and 'validation.csv' are in the correct directory.\")\n",
    "    # Create empty dataframes to avoid further errors\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "# Safely convert the 'target_nouns' column from its string representation back to a list\n",
    "if 'target_nouns' in val_df.columns:\n",
    "    val_df['target_nouns'] = val_df['target_nouns'].fillna('[]').apply(ast.literal_eval)\n",
    "else:\n",
    "    print(\"Warning: 'target_nouns' column not found. Noun accuracy cannot be calculated.\")\n",
    "\n",
    "# Define the prefix for our spell correction task\n",
    "prefix = \"correct the spelling: \"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Prepares the DataFrame for T5 by adding the prefix and selecting columns.\"\"\"\n",
    "    if df.empty: return df\n",
    "    df['incorrect_cleaned_advanced'] = df['incorrect_cleaned_advanced'].astype(str)\n",
    "    df['correct_cleaned_advanced'] = df['correct_cleaned_advanced'].astype(str)\n",
    "    df['input_text'] = prefix + df['incorrect_cleaned_advanced']\n",
    "    df['target_text'] = df['correct_cleaned_advanced']\n",
    "    return df\n",
    "\n",
    "train_df = preprocess_data(train_df)\n",
    "val_df = preprocess_data(val_df)\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Dataset objects\n",
    "if not train_df.empty:\n",
    "    train_dataset = Dataset.from_pandas(train_df[['input_text', 'target_text']])\n",
    "    val_dataset = Dataset.from_pandas(val_df[['input_text', 'target_text']])\n",
    "    print(\"Data prepared and converted to Hugging Face Dataset objects.\")\n",
    "    print(\"\\nSample from training data:\")\n",
    "    print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ca755",
   "metadata": {},
   "source": [
    "### Evaluation Metrics Setup\n",
    "\n",
    "This cell defines the three functions used to evaluate our models:\n",
    "1. Word Accuracy: Percentage of correctly predicted words.\n",
    "2. Noun Accuracy: Percentage of target medical nouns found in the prediction.\n",
    "3. BLEU Score: A measure of similarity between the predicted and true sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa2c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def calculate_word_accuracy(df, true_col, pred_col):\n",
    "    \"\"\"Calculates the percentage of correctly predicted words.\"\"\"\n",
    "    total_words, correct_words = 0, 0\n",
    "    for _, row in df.iterrows():\n",
    "        true_words = str(row[true_col]).split()\n",
    "        pred_words = str(row[pred_col]).split()\n",
    "        for i in range(min(len(true_words), len(pred_words))):\n",
    "            if true_words[i] == pred_words[i]:\n",
    "                correct_words += 1\n",
    "        total_words += len(true_words)\n",
    "    return (correct_words / total_words) * 100 if total_words > 0 else 0\n",
    "\n",
    "def calculate_noun_accuracy(df, true_nouns_col, pred_sent_col):\n",
    "    \"\"\"Calculates the percentage of target nouns found in the predicted sentence.\"\"\"\n",
    "    if true_nouns_col not in df.columns: return 0.0\n",
    "    total_true_nouns, correctly_predicted_nouns = 0, 0\n",
    "    for _, row in df.iterrows():\n",
    "        true_nouns = set(row[true_nouns_col])\n",
    "        pred_doc = nlp(str(row[pred_sent_col]))\n",
    "        pred_nouns = set([token.text for token in pred_doc if token.pos_ in ('NOUN', 'PROPN')])\n",
    "        correctly_predicted_nouns += len(true_nouns.intersection(pred_nouns))\n",
    "        total_true_nouns += len(true_nouns)\n",
    "    return (correctly_predicted_nouns / total_true_nouns) * 100 if total_true_nouns > 0 else 0\n",
    "\n",
    "def calculate_bleu_score(df, true_col, pred_col):\n",
    "    \"\"\"Calculates the average BLEU score for the predictions.\"\"\"\n",
    "    bleu_scores = []\n",
    "    chencherry = SmoothingFunction()\n",
    "    for _, row in df.iterrows():\n",
    "        reference = [str(row[true_col]).split()]\n",
    "        candidate = str(row[pred_col]).split()\n",
    "        score = sentence_bleu(reference, candidate, smoothing_function=chencherry.method1) if candidate else 0\n",
    "        bleu_scores.append(score)\n",
    "    return np.mean(bleu_scores) * 100 if bleu_scores else 0\n",
    "\n",
    "print(\"Evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a6d02",
   "metadata": {},
   "source": [
    "#### Model Training Function\n",
    "\n",
    "- This function encapsulates the entire training process for a T5 model.\n",
    "- It handles tokenization, setting up the trainer, and running the fine-tuning process.\n",
    "- After training, it saves the final model to a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea51fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training function defined.\n"
     ]
    }
   ],
   "source": [
    "def train_model(model_checkpoint, output_dir, train_ds, val_ds):\n",
    "    \"\"\"Handles the tokenization and training of a T5 model.\"\"\"\n",
    "    print(f\"\\n{'='*30}\\nStarting Training for: {model_checkpoint}\\n{'='*30}\")\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "        \n",
    "    tokenized_train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "    tokenized_val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "    print(f\"Tokenization complete for {model_checkpoint}.\")\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir, evaluation_strategy=\"epoch\", learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "        weight_decay=0.01, save_total_limit=3, num_train_epochs=5,\n",
    "        predict_with_generate=True, fp16=(device == \"cuda\"), push_to_hub=False,\n",
    "    )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model, args=training_args, train_dataset=tokenized_train_ds,\n",
    "        eval_dataset=tokenized_val_ds, tokenizer=tokenizer, data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    print(f\"Fine-tuning {model_checkpoint}...\")\n",
    "    trainer.train()\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    final_model_path = f\"{output_dir}/final_model\"\n",
    "    trainer.save_model(final_model_path)\n",
    "    print(f\"Final model saved to '{final_model_path}'\")\n",
    "\n",
    "print(\"Model training function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685d2e6",
   "metadata": {},
   "source": [
    "### Train the General-Purpose `t5-base` Model\n",
    "\n",
    "- now call our training function to fine-tune the standard `t5-base` model.\n",
    "- This will serve as our second baseline, against which can compare the domain-specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81ddbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Starting Training for: t5-base\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb129226d95044508557618b91b7e952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f515efdef3794eb0ade200dde87c8917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete for t5-base.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_23380\\3950277222.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning t5-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be9699fd38048adafbb0efe3c7de866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1ea5687c0c49e6a6b98c7ba5d9b9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11156893521547318, 'eval_runtime': 27.7351, 'eval_samples_per_second': 54.083, 'eval_steps_per_second': 3.389, 'epoch': 1.0}\n",
      "{'loss': 0.8416, 'grad_norm': 0.24801267683506012, 'learning_rate': 1.5470319634703196e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb897d280c4be5a7861b5ebd412e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10265593975782394, 'eval_runtime': 28.0595, 'eval_samples_per_second': 53.458, 'eval_steps_per_second': 3.35, 'epoch': 2.0}\n",
      "{'loss': 0.1158, 'grad_norm': 0.25450220704078674, 'learning_rate': 1.091324200913242e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2744888aede9426981619bed06081327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.099215567111969, 'eval_runtime': 27.8035, 'eval_samples_per_second': 53.95, 'eval_steps_per_second': 3.381, 'epoch': 3.0}\n",
      "{'loss': 0.1089, 'grad_norm': 0.21131180226802826, 'learning_rate': 6.3470319634703205e-06, 'epoch': 3.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae8e2382d18408887fbc7a8117aa425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09739189594984055, 'eval_runtime': 21.2333, 'eval_samples_per_second': 70.644, 'eval_steps_per_second': 4.427, 'epoch': 4.0}\n",
      "{'loss': 0.1052, 'grad_norm': 0.22745051980018616, 'learning_rate': 1.7808219178082193e-06, 'epoch': 4.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee94b01061b482daac01f6f6edf0600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09657690674066544, 'eval_runtime': 21.2268, 'eval_samples_per_second': 70.665, 'eval_steps_per_second': 4.428, 'epoch': 5.0}\n",
      "{'train_runtime': 2762.5045, 'train_samples_per_second': 12.67, 'train_steps_per_second': 0.793, 'train_loss': 0.2765340021211807, 'epoch': 5.0}\n",
      "Training complete.\n",
      "Final model saved to '../models/t5_base_results/final_model'\n"
     ]
    }
   ],
   "source": [
    "if not train_df.empty:\n",
    "    train_model(\n",
    "        model_checkpoint=\"t5-base\",\n",
    "        output_dir=\"../models/t5_base_results\",\n",
    "        train_ds=train_dataset,\n",
    "        val_ds=val_dataset\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping training as data is not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e95f7",
   "metadata": {},
   "source": [
    "### Train the Domain-Specific `Clinical-T5-Large` Model\n",
    "\n",
    "- Next, train the model pre-trained on biomedical and PubMed data.\n",
    "- expecting this model to perform better due to its specialized vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773bfd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ab9e7b677429fb534ee72da3db436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8928d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Starting Training for: razent/SciFive-base-Pubmed_PMC\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73559fcb5fb548f5a30936eff5cdf368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ff88a2e52342e695fd15df06983116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete for razent/SciFive-base-Pubmed_PMC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_32136\\3950277222.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning razent/SciFive-base-Pubmed_PMC...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cf754c6f45418ea25a406919711c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604573e35e2d44fc998fc79845132af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10813253372907639, 'eval_runtime': 14.1481, 'eval_samples_per_second': 106.021, 'eval_steps_per_second': 6.644, 'epoch': 1.0}\n",
      "{'loss': 1.4578, 'grad_norm': 0.2157183140516281, 'learning_rate': 1.5461187214611872e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416ec9efaf6f4681af0f74744e289c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09798427671194077, 'eval_runtime': 9.9714, 'eval_samples_per_second': 150.43, 'eval_steps_per_second': 9.427, 'epoch': 2.0}\n",
      "{'loss': 0.1136, 'grad_norm': 0.2832963764667511, 'learning_rate': 1.0894977168949771e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f3233c9bc9432cbbb985334c61f135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09384094178676605, 'eval_runtime': 21.5322, 'eval_samples_per_second': 69.663, 'eval_steps_per_second': 4.366, 'epoch': 3.0}\n",
      "{'loss': 0.106, 'grad_norm': 0.17183993756771088, 'learning_rate': 6.328767123287672e-06, 'epoch': 3.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdddcbad4374d3da73360d0e91d8f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09217946231365204, 'eval_runtime': 23.4385, 'eval_samples_per_second': 63.997, 'eval_steps_per_second': 4.011, 'epoch': 4.0}\n",
      "{'loss': 0.1026, 'grad_norm': 0.19093696773052216, 'learning_rate': 1.762557077625571e-06, 'epoch': 4.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59818e741cfe47619a0a3325d710485b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0914832353591919, 'eval_runtime': 21.3391, 'eval_samples_per_second': 70.293, 'eval_steps_per_second': 4.405, 'epoch': 5.0}\n",
      "{'train_runtime': 4196.5073, 'train_samples_per_second': 8.34, 'train_steps_per_second': 0.522, 'train_loss': 0.41514865927500266, 'epoch': 5.0}\n",
      "Training complete.\n",
      "Final model saved to '../models/SciFive-base-Pubmed_PMC/final_model'\n"
     ]
    }
   ],
   "source": [
    "if not train_df.empty:\n",
    "    train_model(\n",
    "        model_checkpoint=\"razent/SciFive-base-Pubmed_PMC\",\n",
    "        output_dir=\"../models/SciFive-base-Pubmed_PMC\",\n",
    "        train_ds=train_dataset,\n",
    "        val_ds=val_dataset\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping training as data is not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15303a12",
   "metadata": {},
   "source": [
    "#### Inference Function\n",
    "- This function loads a fine-tuned model from a given path and uses it to\n",
    "generate predictions (inference) for all sentences in our validation set.\n",
    "\n",
    "- We now use our inference function to get predictions from both the `t5-base`\n",
    "and the `BioMed-T5` models. The results are stored in new columns in our\n",
    "validation DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d617f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Running Inference for model at: ../models/t5_base_results/final_model\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc38a2032704c3baf3461a1714a52fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete for ../models/t5_base_results/final_model.\n",
      "\n",
      "==============================\n",
      "Running Inference for model at: ../models/SciFive-base-Pubmed_PMC/final_model\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0dc3dcec0242a7a96aaeb8710eba1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete for ../models/SciFive-base-Pubmed_PMC/final_model.\n",
      "\n",
      "Predictions from both models have been added to the validation DataFrame.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def run_inference(model_path, validation_df):\n",
    "    \"\"\"Loads a saved model and generates predictions.\"\"\"\n",
    "    print(f\"\\n{'='*30}\\nRunning Inference for model at: {model_path}\\n{'='*30}\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "    \n",
    "    predictions = []\n",
    "    for text in tqdm(validation_df['input_text']):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "        outputs = model.generate(inputs, max_length=128, num_beams=8, early_stopping=True)\n",
    "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    print(f\"Inference complete for {model_path}.\")\n",
    "    return predictions\n",
    "\n",
    "if not val_df.empty:\n",
    "    # Get predictions from the general-purpose model\n",
    "    t5_base_predictions = run_inference(\n",
    "        model_path=\"../models/t5_base_results/final_model\",\n",
    "        validation_df=val_df\n",
    "    )\n",
    "    val_df['t5_base_predicted'] = t5_base_predictions\n",
    "\n",
    "    # Get predictions from the domain-specific model\n",
    "    biomed_t5_predictions = run_inference(\n",
    "        model_path=\"../models/SciFive-base-Pubmed_PMC/final_model\",\n",
    "        validation_df=val_df\n",
    "    )\n",
    "    val_df['biomed_t5_predicted'] = biomed_t5_predictions\n",
    "    \n",
    "    print(\"\\nPredictions from both models have been added to the validation DataFrame.\")\n",
    "else:\n",
    "    print(\"Skipping inference as validation data is not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03348750",
   "metadata": {},
   "source": [
    "#### Calculate and Display Final Metrics\n",
    "\n",
    "This is the final step. We calculate all evaluation metrics for both models\n",
    "and display them in a clear summary table for easy comparison. The final\n",
    "DataFrame with all predictions is then saved to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9824f31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "           PERFORMANCE SUMMARY\n",
      "========================================\n",
      "    Model Word Accuracy (%) Noun Accuracy (%) BLEU Score\n",
      "  T5-Base             77.16             73.32      81.62\n",
      "BioMed-T5             77.83             73.63      81.86\n",
      "\n",
      "Final predictions saved to 'validation_with_all_predictions.csv'\n",
      "\n",
      "Displaying a few sample predictions from both models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_cleaned_advanced</th>\n",
       "      <th>t5_base_predicted</th>\n",
       "      <th>biomed_t5_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "      <td>patients are recommended to consult their heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amydio forte is a powerful medication often us...</td>\n",
       "      <td>imidio forte is a powerful medication often us...</td>\n",
       "      <td>imidio forte is a powerful medication often us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>provera 40 contains medroxyprogesterone acetat...</td>\n",
       "      <td>provera-40 contains medrexiprogesterone acetat...</td>\n",
       "      <td>provera-40 contains medroxyprogesterone acetat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ceemi-o is a popular over-the-counter medicati...</td>\n",
       "      <td>simi-oh is a popular over-the-counter medicati...</td>\n",
       "      <td>simi-oh is a popular over-the-counter medicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l-arginine sr is a popular supplement known fo...</td>\n",
       "      <td>lrg9-sr is a popular supplement known for its ...</td>\n",
       "      <td>lrg9-sr is a popular supplement known for its ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correct_cleaned_advanced  \\\n",
       "0  patients are recommended to consult their heal...   \n",
       "1  amydio forte is a powerful medication often us...   \n",
       "2  provera 40 contains medroxyprogesterone acetat...   \n",
       "3  ceemi-o is a popular over-the-counter medicati...   \n",
       "4  l-arginine sr is a popular supplement known fo...   \n",
       "\n",
       "                                   t5_base_predicted  \\\n",
       "0  patients are recommended to consult their heal...   \n",
       "1  imidio forte is a powerful medication often us...   \n",
       "2  provera-40 contains medrexiprogesterone acetat...   \n",
       "3  simi-oh is a popular over-the-counter medicati...   \n",
       "4  lrg9-sr is a popular supplement known for its ...   \n",
       "\n",
       "                                 biomed_t5_predicted  \n",
       "0  patients are recommended to consult their heal...  \n",
       "1  imidio forte is a powerful medication often us...  \n",
       "2  provera-40 contains medroxyprogesterone acetat...  \n",
       "3  simi-oh is a popular over-the-counter medicati...  \n",
       "4  lrg9-sr is a popular supplement known for its ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 't5_base_predicted' in val_df.columns:\n",
    "    models_to_evaluate = {\n",
    "        \"T5-Base\": \"t5_base_predicted\",\n",
    "        \"BioMed-T5\": \"biomed_t5_predicted\"\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for model_name, pred_col in models_to_evaluate.items():\n",
    "        word_acc = calculate_word_accuracy(val_df, 'correct_cleaned_advanced', pred_col)\n",
    "        noun_acc = calculate_noun_accuracy(val_df, 'target_nouns', pred_col)\n",
    "        bleu = calculate_bleu_score(val_df, 'correct_cleaned_advanced', pred_col)\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Word Accuracy (%)\": f\"{word_acc:.2f}\",\n",
    "            \"Noun Accuracy (%)\": f\"{noun_acc:.2f}\",\n",
    "            \"BLEU Score\": f\"{bleu:.2f}\"\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"\\n\\n{'='*40}\\n           PERFORMANCE SUMMARY\\n{'='*40}\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    output_csv_path = 'validation_with_all_predictions.csv'\n",
    "    val_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nFinal predictions saved to '{output_csv_path}'\")\n",
    "    \n",
    "    print(\"\\nDisplaying a few sample predictions from both models:\")\n",
    "    display(val_df[['correct_cleaned_advanced', 't5_base_predicted', 'biomed_t5_predicted']].head())\n",
    "else:\n",
    "    print(\"Skipping evaluation as predictions were not generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
